{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Accuracy: 0.950354609929078\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        56\n",
      "           1       0.91      0.94      0.92        62\n",
      "           2       0.88      0.88      0.88        56\n",
      "           3       0.96      0.92      0.94        50\n",
      "           4       0.96      0.96      0.96        78\n",
      "           5       0.97      0.97      0.97        58\n",
      "           6       0.98      1.00      0.99        63\n",
      "\n",
      "    accuracy                           0.95       423\n",
      "   macro avg       0.95      0.95      0.95       423\n",
      "weighted avg       0.95      0.95      0.95       423\n",
      "\n",
      "----------------------\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "----------------------\n",
      "Model: SVC\n",
      "Accuracy: 0.8652482269503546\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        56\n",
      "           1       0.80      0.73      0.76        62\n",
      "           2       0.68      0.71      0.70        56\n",
      "           3       0.71      0.70      0.71        50\n",
      "           4       0.93      0.97      0.95        78\n",
      "           5       0.97      0.98      0.97        58\n",
      "           6       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           0.87       423\n",
      "   macro avg       0.86      0.86      0.86       423\n",
      "weighted avg       0.86      0.87      0.86       423\n",
      "\n",
      "----------------------\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "----------------------\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 0.7943262411347518\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        56\n",
      "           1       0.66      0.44      0.52        62\n",
      "           2       0.68      0.64      0.66        56\n",
      "           3       0.55      0.66      0.60        50\n",
      "           4       0.85      0.86      0.85        78\n",
      "           5       0.92      0.98      0.95        58\n",
      "           6       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           0.79       423\n",
      "   macro avg       0.78      0.79      0.78       423\n",
      "weighted avg       0.79      0.79      0.79       423\n",
      "\n",
      "----------------------\n",
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "----------------------\n",
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 0.9432624113475178\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        56\n",
      "           1       0.95      0.89      0.92        62\n",
      "           2       0.93      0.95      0.94        56\n",
      "           3       0.96      0.92      0.94        50\n",
      "           4       0.94      0.94      0.94        78\n",
      "           5       0.95      0.93      0.94        58\n",
      "           6       0.97      1.00      0.98        63\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "----------------------\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "----------------------\n",
      "Prediction: [3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "try:\n",
    "    # Step 1: Load the dataset\n",
    "    dataset_path = \"ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Step 2: Preprocess the data\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(['Gender', 'family_history_with_overweight','FAVC','CAEC','SMOKE','SCC','CALC','MTRANS'], axis=1)\n",
    "\n",
    "    # Convert the target variable to numerical labels\n",
    "    class_mapping = {\n",
    "        'Insufficient_Weight': 0,\n",
    "        'Normal_Weight': 1,\n",
    "        'Overweight_Level_I': 2,\n",
    "        'Overweight_Level_II': 3,\n",
    "        'Obesity_Type_I': 4,\n",
    "        'Obesity_Type_II': 5,\n",
    "        'Obesity_Type_III': 6\n",
    "    }\n",
    "    df['NObeyesdad'] = df['NObeyesdad'].map(class_mapping)\n",
    "\n",
    "    # Separate features (X) and target variable (y)\n",
    "    X = df.drop(['NObeyesdad'], axis=1)\n",
    "    y = df['NObeyesdad']\n",
    "\n",
    "    # Step 3: Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 4: Apply feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Step 5: Train the classification models\n",
    "    models = [\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        SVC(random_state=42),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(random_state=42)\n",
    "    ]\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for model in models:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        print(\"Model:\", type(model).__name__)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "        print(\"----------------------\")\n",
    "\n",
    "        # Step 6: Fine-tune the models (if necessary)\n",
    "        if type(model).__name__ == 'RandomForestClassifier':\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 150],\n",
    "                'max_depth': [None, 5, 10],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "            print(\"Best parameters:\", best_params)\n",
    "\n",
    "            # Re-train the model with the best parameters\n",
    "            model = RandomForestClassifier(random_state=42, **best_params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        elif type(model).__name__ == 'SVC':\n",
    "            param_grid = {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "            }\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "            print(\"Best parameters:\", best_params)\n",
    "\n",
    "            # Re-train the model with the best parameters\n",
    "            model = SVC(random_state=42, **best_params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        elif type(model).__name__ == 'KNeighborsClassifier':\n",
    "            param_grid = {\n",
    "                'n_neighbors': [3, 5, 7],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'metric': ['euclidean', 'manhattan']\n",
    "            }\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "            print(\"Best parameters:\", best_params)\n",
    "\n",
    "            # Re-train the model with the best parameters\n",
    "            model = KNeighborsClassifier(**best_params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        elif type(model).__name__ == 'DecisionTreeClassifier':\n",
    "            param_grid = {\n",
    "                'max_depth': [None, 5, 10],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "            print(\"Best parameters:\", best_params)\n",
    "\n",
    "            # Re-train the model with the best parameters\n",
    "            model = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "        print(\"----------------------\")\n",
    "\n",
    "    # Step 8: Predict on new data\n",
    "    new_data = pd.DataFrame({\n",
    "        'Age': [21],\n",
    "        'Height': [1.75],\n",
    "        'Weight': [88],\n",
    "        'FCVC': [2],\n",
    "        'NCP': [3],\n",
    "        'CH2O': [3],\n",
    "        'FAF': [3],\n",
    "        'TUE': [0]\n",
    "    })\n",
    "\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    prediction = model.predict(new_data_scaled)\n",
    "    print(\"Prediction:\", prediction)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
